{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch Jupyter Noteboook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import tqdm  \n",
    "import activations\n",
    "import params\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nonlinear_params = {\n",
    "    'alpha': 900,\n",
    "    'beta':  -.06045,\n",
    "    'r': 3.99,\n",
    "    'mu': 1.99\n",
    "}\n",
    "\n",
    "num_samples_train = 10000\n",
    "num_samples_test = 1000\n",
    "\n",
    "\n",
    "config = params.RegressionParams(\n",
    "    width = 1000,\n",
    "    depth = 50,\n",
    "    input_dimension = 2,\n",
    "    transform_type = params.TransformType.TENT,\n",
    "    transform_params = params.TentParams(\n",
    "        mu = 1.99\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(x: NDArray) -> int:\n",
    "\n",
    "    if x[0] >= 0:\n",
    "        # First or Fourth Quadrants\n",
    "        if x[1] >= 0:\n",
    "            # First Quadrant\n",
    "                return 0\n",
    "            # Fourth Quadrant\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    # Second or Third Quadrants\n",
    "    else:\n",
    "        # Second Quadrant\n",
    "        if x[1] >= 0:\n",
    "            return 1\n",
    "        \n",
    "        # Fourth Quadrant\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Preferred Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jnp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m neurons = np.random.normal(loc=\u001b[32m0\u001b[39m, scale=\u001b[32m1\u001b[39m, size=(config.input_dimension, config.width))\n\u001b[32m      2\u001b[39m neurons = neurons / np.linalg.norm(neurons, axis=\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m neurons = \u001b[43mjnp\u001b[49m.asarray(neurons)\n\u001b[32m      4\u001b[39m plt.scatter(neurons[\u001b[32m0\u001b[39m,:], neurons[\u001b[32m1\u001b[39m,:])\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mRandomly Sampled Neuron \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPreferred Directions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m along the Unit Hypersphere (d=2)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'jnp' is not defined"
     ]
    }
   ],
   "source": [
    "neurons = np.random.normal(loc=0, scale=1, size=(config.input_dimension, config.width))\n",
    "neurons = neurons / np.linalg.norm(neurons, axis=0)\n",
    "neurons = np.asarray(neurons)\n",
    "plt.scatter(neurons[0,:], neurons[1,:])\n",
    "plt.title(\"Randomly Sampled Neuron 'Preferred Directions' along the Unit Hypersphere (d=2)\")\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Neural Nonlinear Activation Function\")\n",
    "xs = np.asarray(np.linspace(-1.5, 1.5, num=1000))\n",
    "# plt.plot(xs, gauss(xs, alpha=nonlinear_params['alpha'], beta=nonlinear_params['beta']))\n",
    "plt.plot(xs, activations.tent(xs, params=config.transform_params))\n",
    "\n",
    "# plt.xlim([-1, 1])\n",
    "# plt.ylim(-1,1)\n",
    "plt.xlabel(\"x\")\n",
    "plt.axhline(0, c='k')\n",
    "plt.axvline(0, c='k')\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_126679/2775879322.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = cm.get_cmap('inferno', config.depth+1)\n"
     ]
    },
    {
     "ename": "NonConcreteBooleanIndexError",
     "evalue": "Array boolean indices must be concrete; got ShapedArray(bool[1,1000,2])\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNonConcreteBooleanIndexError\u001b[39m              Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_126679/2775879322.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m colors = cm.get_cmap(\u001b[33m'inferno'\u001b[39m, config.depth+\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m activations_identity = activations.compute_activations(neurons, jnp.asarray(np.eye(\u001b[32m2\u001b[39m)), config)\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m plt.scatter(neurons[\u001b[32m0\u001b[39m,:], neurons[\u001b[32m1\u001b[39m,:], color=\u001b[33m\"black\"\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 15 frame]\u001b[39m\n",
      "\u001b[32m~/untitled/src/nonlinear_approximator/activations.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(neurons, input_x, config)\u001b[39m\n\u001b[32m    102\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m idx_layer == \u001b[32m0\u001b[39m:\n\u001b[32m    103\u001b[39m             activations[idx_layer, :, :] = neurons.T @ input_x\n\u001b[32m    104\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    105\u001b[39m             activations[idx_layer, :, :] = transform(\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m                 activations[idx_layer-\u001b[32m1\u001b[39m, :, :],\n\u001b[32m    107\u001b[39m                 config.transform_params\n\u001b[32m    108\u001b[39m             )\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m activations\n",
      "\u001b[32m~/untitled/src/nonlinear_approximator/activations.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, params)\u001b[39m\n\u001b[32m     61\u001b[39m     Returns:\n\u001b[32m     62\u001b[39m         float | NDArray[np.floating]: The mapped value \u001b[38;5;28;01mor\u001b[39;00m array, matching the type of data input.\n\u001b[32m     63\u001b[39m     \"\"\"\n\u001b[32m     64\u001b[39m     out = params.mu * (\u001b[32m1\u001b[39m + x)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     out[x > \u001b[32m0\u001b[39m] = params.mu * (\u001b[32m1\u001b[39m - x[x > \u001b[32m0\u001b[39m])\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# TODO: maybe reword neurons here to reflect they're  sensors\u001b[39;00m\n",
      "\u001b[32m~/untitled/.venv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1060\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m op(self, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m getattr(self.aval, \u001b[33mf\"_{name}\"\u001b[39m)(self, *args)\n",
      "\u001b[32m~/untitled/.venv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m _getitem(self, item):\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_numpy._rewriting_take(self, item)\n",
      "\u001b[32m~/untitled/.venv/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[39m\n\u001b[32m  11961\u001b[39m           \u001b[38;5;28;01mnot\u001b[39;00m dtypes.issubdtype(aval.dtype, dtypes.bool_) \u001b[38;5;28;01mand\u001b[39;00m\n\u001b[32m  11962\u001b[39m           isinstance(arr.shape[0], int)):\n\u001b[32m  11963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m lax.dynamic_index_in_dim(arr, idx, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m  11964\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m11965\u001b[39m   treedef, static_idx, dynamic_idx = _split_index_for_jit(idx, arr.shape)\n\u001b[32m  11966\u001b[39m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[32m  11967\u001b[39m                  unique_indices, mode, fill_value)\n",
      "\u001b[32m~/untitled/.venv/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m  12046\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33mf\"JAX does not support string indexing; got {idx=}\"\u001b[39m)\n\u001b[32m  12047\u001b[39m \n\u001b[32m  12048\u001b[39m   \u001b[38;5;66;03m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[32m  12049\u001b[39m   \u001b[38;5;66;03m# indexing logic to handle them.\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12050\u001b[39m   idx = _expand_bool_indices(idx, shape)\n\u001b[32m  12051\u001b[39m \n\u001b[32m  12052\u001b[39m   leaves, treedef = tree_flatten(idx)\n\u001b[32m  12053\u001b[39m   dynamic = [\u001b[38;5;28;01mNone\u001b[39;00m] * len(leaves)\n",
      "\u001b[32m~/untitled/.venv/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m  12347\u001b[39m         abstract_i = core.get_aval(i)\n\u001b[32m  12348\u001b[39m \n\u001b[32m  12349\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m core.is_concrete(i):\n\u001b[32m  12350\u001b[39m         \u001b[38;5;66;03m# TODO(mattjj): improve this error by tracking _why_ the indices are not concrete\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m errors.NonConcreteBooleanIndexError(abstract_i)\n\u001b[32m  12352\u001b[39m       \u001b[38;5;28;01melif\u001b[39;00m _ndim(i) == \u001b[32m0\u001b[39m:\n\u001b[32m  12353\u001b[39m         out.append(bool(i))\n\u001b[32m  12354\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNonConcreteBooleanIndexError\u001b[39m: Array boolean indices must be concrete; got ShapedArray(bool[1,1000,2])\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError"
     ]
    }
   ],
   "source": [
    "colors = cm.get_cmap('inferno', config.depth+1)\n",
    "\n",
    "\n",
    "activations_identity = activations.compute_activations(neurons, np.asarray(np.eye(2)), config)\n",
    "\n",
    "\n",
    "plt.scatter(neurons[0,:], neurons[1,:], color=\"black\")\n",
    "for idx_layer in range(1,config.depth): \n",
    "    plt.scatter(activations_identity[idx_layer, :, 0], activations_identity[idx_layer, :, 1], label=f\"Pass {idx_layer+1}\", c=colors(idx_layer+1))\n",
    "    \n",
    "# plt.xlim([-1.25, 1.25])\n",
    "# plt.ylim([-1.25, 1.25])\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# acts has shape (depth, num_neurons, num_samples)\n",
    "test_samples = np.random.normal(loc=0, scale=1, size=(config.input_dimension, num_samples_test))\n",
    "test_samples /= np.linalg.norm(test_samples,axis=0)\n",
    "train_samples = np.random.normal(loc=0, scale=1, size=(num_dims, num_samples_train))\n",
    "train_samples /= np.linalg.norm(train_samples,axis=0)\n",
    "\n",
    "# Scale by radii distributed according to d^th root (where d is dimension) to get uniform density \n",
    "test_radii = np.random.uniform(0, 1, size=num_samples_test)\n",
    "train_radii = np.random.uniform(0, 1, size=num_samples_train)\n",
    "test_samples *= np.sqrt(test_radii)\n",
    "train_samples *= np.sqrt(train_radii)\n",
    "\n",
    "\n",
    "# Batch compute activations\n",
    "activations_train = forward_pass(neurons, input_x=train_samples, n_layers=depth, params=nonlinear_params) # np.zeros((n_layers, num_neurons, num_samples_train)) \n",
    "activations_test =  forward_pass(neurons, input_x=test_samples, n_layers=depth, params=nonlinear_params) # np.zeros((n_layers, num_neurons, num_samples_train)) \n",
    "\n",
    "\n",
    "# Compute XOR, then use making to plot classification\n",
    "xors_train = np.array([xor(train_samples[:, i]) for i in range(num_samples_train)])\n",
    "\n",
    "mask_0 = xors_train == 0\n",
    "mask_1 = xors_train == 1\n",
    "plt.scatter(train_samples[0,mask_0], train_samples[1,mask_0], c='red', marker='x', label='XOR = 0')\n",
    "plt.scatter(train_samples[0,mask_1], train_samples[1,mask_1], c='green', marker='o', label='XOR = 1')\n",
    "        \n",
    "plt.axis('equal')\n",
    "plt.axvline(x=0, c='black')\n",
    "plt.axhline(y=0, c='black')\n",
    "\n",
    "plt.title(\"XOR Function\")\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an XOR Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acts has shape (depth, num_neurons, num_samples)\n",
    "acts_flat = activations_train.reshape((depth*num_neurons, num_samples_train))\n",
    "\n",
    "decoder = np.linalg.lstsq(acts_flat.T, xors_train)[0]Lo\n",
    "\n",
    "xors_recovered = decoder @ acts_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_thresh = 0.5 \n",
    "\n",
    "mask_0 = np.isclose(xors_recovered, 0)\n",
    "mask_1 = np.isclose(xors_recovered, 1)\n",
    "plt.scatter(train_samples[0,mask_0], train_samples[1,mask_0], c='red', marker='x', label='XOR = 0')\n",
    "plt.scatter(train_samples[0,mask_1], train_samples[1,mask_1], c='green', marker='o', label='XOR = 1')\n",
    "\n",
    "xors_train_rounded = xors_recovered.copy()\n",
    "xors_train_rounded[xors_train_rounded <= xor_thresh] = 0\n",
    "xors_train_rounded[xors_train_rounded > xor_thresh] = 1\n",
    "xor_train_actual = np.array([xor(train_samples[:, i]) for i in range(train_samples.shape[1])])\n",
    "\n",
    "for i in range(train_samples.shape[1]):\n",
    "    if xors_train_rounded[i] != xor_train_actual[i]:\n",
    "        plt.scatter(train_samples[0,i], train_samples[1,i], marker='+',c='yellow')\n",
    "        \n",
    "plt.axis('equal')\n",
    "plt.axvline(x=0, c='black')\n",
    "plt.axhline(y=0, c='black')\n",
    "\n",
    "plt.title(f\"Network Approximation of XOR function  (Applied to Training Data)\\nAccuracy = {100 *sum(xors_train_rounded==xor_train_actual)/num_samples_train}%\")\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xors_test_recovered = decoder @ activations_test.reshape((depth*num_neurons, num_samples_test))\n",
    "plt.hist(xors_test_recovered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Test XOR Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xors_test_recovered = decoder @ activations_test.reshape((depth*num_neurons, num_samples_test))\n",
    "xors_test_recovered[xors_test_recovered <=  xor_thresh] = 0\n",
    "xors_test_recovered[xors_test_recovered >  xor_thresh] = 1\n",
    "\n",
    "mask_test_0 = xors_test_recovered  <= xor_thresh\n",
    "mask_test_1 = xors_test_recovered  > xor_thresh\n",
    "plt.scatter(test_samples[0,mask_test_0], test_samples[1,mask_test_0], c='red', marker='x', label='XOR = 0')\n",
    "plt.scatter(test_samples[0,mask_test_1], test_samples[1,mask_test_1], c='green', marker='o', label='XOR = 1')\n",
    "\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "    \n",
    "xors_test_actual = np.array([xor(test_samples[:, i]) for i in range(num_samples_test)])\n",
    "\n",
    "# for i in range(num_samples_test):\n",
    "#     if not xors_test_recovered[i] == xors_test_actual[i]:\n",
    "#         plt.scatter(test_samples[0,i], test_samples[1,i], marker='+',c='yellow')\n",
    "        \n",
    "\n",
    "plt.title(f\"Network Approximation of XOR function  (Applied to Test Data)\\nAccuracy = {100 *sum(xors_test_recovered==xors_test_actual)/num_samples_test}%\")\n",
    "plt.axis('equal')\n",
    "plt.axvline(x=0, c='black')\n",
    "plt.axhline(y=0, c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer-based Training + Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders =[]\n",
    "for idx_layer in tqdm.tqdm(range(depth)):\n",
    "    acts_flat = activations_train[:idx_layer,:, :].reshape((idx_layer*num_neurons, num_samples_train))\n",
    "    decoders.append(np.linalg.lstsq(acts_flat.T, xors_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for decoder in decoders:\n",
    "# infer from decoder\n",
    "#\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "xors_test_actual = np.array([xor(test_samples[:, i]) for i in range(num_samples_test)])\n",
    "xor_train_actual = np.array([xor(train_samples[:, i]) for i in range(train_samples.shape[1])])\n",
    "\n",
    "for idx_decoder, dec in enumerate(decoders):\n",
    "    if idx_decoder > 0:\n",
    "        # train accuracy \n",
    "        xor_est_train = dec @ activations_train[:idx_decoder].reshape(idx_decoder * num_neurons, num_samples_train)              \n",
    "        xor_est_train[xor_est_train < .5] = 0\n",
    "        xor_est_train[xor_est_train >= .5] = 1 \n",
    "        accs_train.append(100 * sum(xor_est_train == xor_train_actual) / num_samples_train)\n",
    "\n",
    "        # test accuracy\n",
    "        xor_est_test = dec @ activations_test[:idx_decoder].reshape(idx_decoder * num_neurons, num_samples_test)\n",
    "        xor_est_test[xor_est_test < .5] = 0\n",
    "        xor_est_test[xor_est_test >= .5] = 1 \n",
    "        accs_test.append(100 * sum(xor_est_test == xors_test_actual) / num_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accs_test), len(accs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accs_train, label=\"Train Classification Accuracy\")\n",
    "plt.plot(accs_test,  label='Test Classification Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.title(\"Test and Training Accuracy\")\n",
    "plt.xlabel(\"Neuron Layers used to fit model\")\n",
    "plt.ylabel(\"Classification Accuracy on Test Set\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_inter = np.zeros((depth-1,))\n",
    "corrs_intra = np.zeros((depth-1,))\n",
    "\n",
    "for idx_layer in range(1, depth-1):\n",
    "    ccf_inter = np.corrcoef(activations_train[idx_layer-1,:,:], activations_train[idx_layer,:,:], )\n",
    "    ccf_inter = ccf_inter - np.eye(ccf_inter.shape[0])\n",
    "\n",
    "    ccf_intra = np.corrcoef(activations_train[idx_layer-1,:,:], activations_train[idx_layer,:,:], )\n",
    "    ccf_intra = ccf_intra - np.eye(ccf_intra.shape[0])\n",
    "    \n",
    "    # zero out intra-layer correlations\n",
    "    ccf_inter[0:num_neurons, 0:num_neurons] = 0\n",
    "    ccf_inter[num_neurons:, num_neurons:] = 0\n",
    "\n",
    "    ccf_intra[0:num_neurons, num_neurons:] = 0\n",
    "    ccf_intra[num_neurons:, 0:num_neurons] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # correlations between layers\n",
    "    corrs_inter[idx_layer] = np.max(np.abs(ccf_inter))\n",
    "    corrs_intra[idx_layer] = np.max(np.abs(ccf_intra))\n",
    "    # correaltions within layers \n",
    "    \n",
    "\n",
    "# plt.imshow(ccf_intra, vmin=-1, vmax=1)\n",
    "# plt.colorbar()\n",
    "# for idx_layer in range(depth):\n",
    "#     pass\n",
    "plt.plot(corrs_inter, label='Inter-layer max correlation')\n",
    "plt.plot(corrs_intra, label='Intra-layer max correlation')\n",
    "plt.xscale('log')\n",
    "plt.xlim([2, depth])\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel(\"Maximum Absolute Pairwise Correlation Over Batch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(100*corrs_inter, label='Inter-layer max correlation')\n",
    "plt.plot(100*corrs_intra, label='Intra-layer max correlation')\n",
    "# plt.xscale('log')\n",
    "plt.xlim([2, depth])\n",
    "plt.xlabel('Layer')\n",
    "# plt.ylabel(\"Maximum Absolute Pairwise Correlation Over Batch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(accs_train, label=\"Train Classification Accuracy\")\n",
    "plt.plot(accs_test,  label='Test Classification Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.title(\"Test and Training Accuracy\")\n",
    "# plt.xlabel(\"Neuron Layers used to fit model\")\n",
    "# plt.ylabel(\"Classification Accuracy on Test Set\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
